{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from string import Template\n",
    "\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "from exllamav2 import (\n",
    "    ExLlamaV2,\n",
    "    ExLlamaV2Config,\n",
    "    ExLlamaV2Cache,\n",
    "    ExLlamaV2Tokenizer,\n",
    "    ExLlamaV2Lora,\n",
    ")\n",
    "\n",
    "from exllamav2.generator import (\n",
    "    ExLlamaV2BaseGenerator,\n",
    "    ExLlamaV2StreamingGenerator,\n",
    "    ExLlamaV2Sampler,\n",
    ")\n",
    "\n",
    "import time\n",
    "\n",
    "# Initialize model and cache\n",
    "\n",
    "model_directory = (\n",
    "    \"/mnt/Woo/text-generation-webui/models/TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ\"\n",
    ")\n",
    "config = ExLlamaV2Config()\n",
    "config.model_dir = model_directory\n",
    "config.prepare()\n",
    "\n",
    "model = ExLlamaV2(config)\n",
    "print(\"Loading model: \" + model_directory)\n",
    "model.load()\n",
    "\n",
    "tokenizer = ExLlamaV2Tokenizer(config)\n",
    "\n",
    "cache = ExLlamaV2Cache(model)\n",
    "\n",
    "# Load LoRA\n",
    "\n",
    "lora_directory = \"/mnt/Woo/text-generation-webui/loras/Wizard-Vicuna-13B-Uncensored-GPTQ-reddit-submissions\"\n",
    "lora = ExLlamaV2Lora.from_directory(model, lora_directory)\n",
    "\n",
    "# Initialize generators\n",
    "\n",
    "streaming_generator = ExLlamaV2StreamingGenerator(model, cache, tokenizer)\n",
    "streaming_generator.warmup()\n",
    "\n",
    "streaming_generator.set_stop_conditions([\"\\nUser:\", tokenizer.eos_token_id])\n",
    "\n",
    "simple_generator = ExLlamaV2BaseGenerator(model, cache, tokenizer)\n",
    "\n",
    "# Sampling settings\n",
    "\n",
    "settings = ExLlamaV2Sampler.Settings()\n",
    "settings.temperature = 0.98\n",
    "settings.top_p = 0.37\n",
    "settings.token_repetition_penalty = 1.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_lora(prompt_, lora_, max_new_tokens):\n",
    "    #print(prompt_, end=\"\")\n",
    "    #sys.stdout.flush()\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt_)\n",
    "\n",
    "    streaming_generator.begin_stream(input_ids, settings, loras=lora_)\n",
    "    generated_tokens = 0\n",
    "    output = \"\"\n",
    "    while True:\n",
    "        chunk, eos, _ = streaming_generator.stream()\n",
    "        generated_tokens += 1\n",
    "        output += chunk\n",
    "        #print(chunk, end=\"\")\n",
    "        #sys.stdout.flush()\n",
    "        if eos or generated_tokens == max_new_tokens:\n",
    "            break\n",
    "\n",
    "    #print()\n",
    "\n",
    "    #print(\"done\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "\n",
    "POST_TEMPLATE = Template(\n",
    "    \"\"\"You are a Reddit post generator.\n",
    "User: \n",
    "Subreddit: $subreddit \n",
    "Author: $author \n",
    "Media: $media \n",
    "Title: $title \n",
    "Write the Reddit post.\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "TAGS = {\n",
    "    \"Subreddit\": \"[SUBREDDIT]\",\n",
    "    \"Author\": \"[AUTHOR]\",\n",
    "    \"Media\": \"[MEDIA]\",\n",
    "    \"Title\": \"[TITLE]\",\n",
    "    \"EOS\": \"\"\"Write the Reddit post.\n",
    "Assistant:\"\"\",\n",
    "}\n",
    "def contains_letter(s):\n",
    "    return any(c.isalpha() for c in s)\n",
    "VALID_MEDIA = [\"image\", \"video\", \"text\", \"article\"] # articles are links to external sites\n",
    "CONSTRAINTS_FUNCS = { # by tag key\n",
    "    \"Subreddit\": lambda x: x.startswith(\"/r/\") and len(x) > len(\"/r/\"),\n",
    "    \"Author\": lambda x: len(x) > 0 and contains_letter(x),\n",
    "    \"Media\": lambda x: x in VALID_MEDIA,\n",
    "    \"Title\": lambda x: len(x) > 0,\n",
    "    \"EOS\": lambda x: x,\n",
    "\n",
    "}\n",
    "\n",
    "POST_TAGS_ORDER_OP = [\n",
    "    TAGS[\"Subreddit\"],\n",
    "    TAGS[\"Author\"],\n",
    "    TAGS[\"Media\"],\n",
    "    TAGS[\"Title\"],\n",
    "    TAGS[\"EOS\"],\n",
    "]  # order matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a Reddit post generator.\n",
      "User: \n",
      "Subreddit: /r/aww \n",
      "Author: 10_gallons_of_gasoline \n",
      "Media: article \n",
      "Title: 23-year-old man who was born with no hands is now the first person in Europe to receive a bionic hand that can do everything from playing piano to opening a bottle of beer \n",
      "Write the Reddit post.\n",
      "Assistant:\n",
      " \n",
      "A 23-year-old man has become the first person in Europe to receive a new type of bionic hand that not only looks like a real human hand but also performs all sorts of tasks, including playing the piano and even opening a bottle of beer. The young man, named Steven Spiers, was born without any hands due to a rare genetic condition called symbrachydactyly, which affects about one in every 30,000 births worldwide. But thanks to advancements in prosthetics technology, he's been able to get his life back on track by using a cutting-edge device known as the \"LimbO.\" Developed by researchers at the University of Glasgow in Scotland, the LimbO features advanced sensors and motors that allow it to mimic the movements of a natural hand, making it possible for users to perform complex tasks such as typing on a keyboard or turning pages in a book. And while traditional prosthetic devices often require extensive training and practice before they can be used effectively, the LimbO requires almost no adjustment period whatsoever - meaning it can be put to use right away. According to Spiers himself, the LimbO has already made a huge difference in his daily life. \"I couldn't believe how easy it was to use,\" he said. \"It feels so much more natural than my old prosthesis did. I feel like I have my independence back again.\" While the LimbO may still be in its early stages of development, researchers hope that it will eventually become available to other people who need assistance with their daily lives. In fact, the team behind the project recently received funding from the European Union to continue developing the device and make it accessible to more people around the world.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def get_up_to_tag_line(prompt, tag):\n",
    "    try:\n",
    "        sub_index = prompt.index(tag)\n",
    "    except ValueError:\n",
    "        print(\"Error: tag not found\")\n",
    "        return -1\n",
    "\n",
    "    # get last \\n before tag\n",
    "    last_newline_index = prompt.rfind(\"\\n\", 0, sub_index)\n",
    "\n",
    "    if last_newline_index == -1:\n",
    "        last_newline_index = 0\n",
    "    # remove  from last_newline_index to newline_index\n",
    "    prompt = prompt[:last_newline_index]\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def get_up_to_tag(prompt, tag):\n",
    "    try:\n",
    "        sub_index = prompt.index(tag)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "    prompt = prompt[:sub_index]\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_post(\n",
    "    subreddit=TAGS[\"Subreddit\"],\n",
    "    author=TAGS[\"Author\"],\n",
    "    media=TAGS[\"Media\"],\n",
    "    title=TAGS[\"Title\"],\n",
    "):\n",
    "    prompt_full = POST_TEMPLATE.substitute(\n",
    "        subreddit=subreddit, author=author, media=media, title=title\n",
    "    )\n",
    "\n",
    "    # loop over tags in order\n",
    "    for tag in POST_TAGS_ORDER_OP:\n",
    "        if tag == TAGS[\"EOS\"]:\n",
    "            # add EOS tag\n",
    "            #prompt_full = f\"{prompt_full}\\n{tag}\"\n",
    "            break\n",
    "        prompt = get_up_to_tag(prompt_full, tag)\n",
    "        if prompt == -1:\n",
    "            continue  # skip tag if not found\n",
    "        #print(prompt)\n",
    "\n",
    "        # get tag key from tag value\n",
    "        tag_key = list(TAGS.keys())[list(TAGS.values()).index(tag)]\n",
    "        next_tag_value = POST_TAGS_ORDER_OP[POST_TAGS_ORDER_OP.index(tag) + 1]\n",
    "        next_tag_key = list(TAGS.keys())[list(TAGS.values()).index(next_tag_value)]\n",
    "        # print(\"Tag: \" + tag_key)\n",
    "        #print(f\"\"\"generate from here to: '\\\\n'\"\"\")\n",
    "        #print()\n",
    "        streaming_generator.set_stop_conditions(\n",
    "            [\"\\n\", \"\\nUser:\", tokenizer.eos_token_id]\n",
    "        )\n",
    "        valid_output = False\n",
    "        while not valid_output:\n",
    "            if tag == \"[MEDIA]\":\n",
    "                # random valid media\n",
    "                output = random.choice(VALID_MEDIA)\n",
    "            else:\n",
    "                output = generate_with_lora(prompt, lora, 250)\n",
    "            output = output.strip()\n",
    "            #print(f\"generated output: {output}\")\n",
    "            valid_output = CONSTRAINTS_FUNCS[tag_key](output)\n",
    "                \n",
    "        # replace tag with output\n",
    "        prompt_full = prompt_full.replace(tag, output)\n",
    "        #prompt = f\"{prompt}{output} \\n{next_tag_key}:}\"\n",
    "\n",
    "    #print(prompt_full)\n",
    "    streaming_generator.set_stop_conditions(\n",
    "            [\"\\nUser:\", tokenizer.eos_token_id]\n",
    "        )\n",
    "    return prompt_full, generate_with_lora(prompt_full, lora, len(prompt_full) + 500)\n",
    "\n",
    "\n",
    "prompt, post = generate_post('/r/aww')\n",
    "print(prompt)\n",
    "print(post)\n",
    "# generate_post(subreddit=\"r/aww\", author=\"u/aww\", media=\"https://i.redd.it/1q2w3e4r5t6y.jpg\", title=\"Cute doggo\")\n",
    "#generate_post(subreddit=\"r/aww\", author=\"u/aww\", media=\"https://i.redd.it/1q2w3e4r5t6y.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingLlama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
