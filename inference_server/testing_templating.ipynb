{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: /mnt/Woo/text-generation-webui/models/TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from string import Template\n",
    "\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "from exllamav2 import (\n",
    "    ExLlamaV2,\n",
    "    ExLlamaV2Config,\n",
    "    ExLlamaV2Cache,\n",
    "    ExLlamaV2Tokenizer,\n",
    "    ExLlamaV2Lora,\n",
    ")\n",
    "\n",
    "from exllamav2.generator import (\n",
    "    ExLlamaV2BaseGenerator,\n",
    "    ExLlamaV2StreamingGenerator,\n",
    "    ExLlamaV2Sampler,\n",
    ")\n",
    "\n",
    "import time\n",
    "\n",
    "# Initialize model and cache\n",
    "\n",
    "model_directory = (\n",
    "    \"/mnt/Woo/text-generation-webui/models/TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ\"\n",
    ")\n",
    "config = ExLlamaV2Config()\n",
    "config.model_dir = model_directory\n",
    "config.prepare()\n",
    "\n",
    "model = ExLlamaV2(config)\n",
    "print(\"Loading model: \" + model_directory)\n",
    "model.load()\n",
    "\n",
    "tokenizer = ExLlamaV2Tokenizer(config)\n",
    "\n",
    "cache = ExLlamaV2Cache(model)\n",
    "\n",
    "# Load LoRA\n",
    "\n",
    "lora_directory = \"/mnt/Woo/text-generation-webui/loras/Wizard-Vicuna-13B-Uncensored-GPTQ-reddit-submissions\"\n",
    "lora = ExLlamaV2Lora.from_directory(model, lora_directory)\n",
    "\n",
    "# Initialize generators\n",
    "\n",
    "streaming_generator = ExLlamaV2StreamingGenerator(model, cache, tokenizer)\n",
    "streaming_generator.warmup()\n",
    "\n",
    "streaming_generator.set_stop_conditions([\"\\nUser:\", tokenizer.eos_token_id])\n",
    "\n",
    "simple_generator = ExLlamaV2BaseGenerator(model, cache, tokenizer)\n",
    "\n",
    "# Sampling settings\n",
    "\n",
    "settings = ExLlamaV2Sampler.Settings()\n",
    "settings.temperature = 0.98\n",
    "settings.top_p = 0.37\n",
    "settings.token_repetition_penalty = 1.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_lora(prompt_, lora_, max_new_tokens):\n",
    "    #print(prompt_, end=\"\")\n",
    "    #sys.stdout.flush()\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt_)\n",
    "\n",
    "    streaming_generator.begin_stream(input_ids, settings, loras=lora_)\n",
    "    generated_tokens = 0\n",
    "    output = \"\"\n",
    "    while True:\n",
    "        chunk, eos, _ = streaming_generator.stream()\n",
    "        generated_tokens += 1\n",
    "        output += chunk\n",
    "        #print(chunk, end=\"\")\n",
    "        #sys.stdout.flush()\n",
    "        if eos or generated_tokens == max_new_tokens:\n",
    "            break\n",
    "\n",
    "    #print()\n",
    "\n",
    "    #print(\"done\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "import string\n",
    "\n",
    "POST_TEMPLATE = Template(\n",
    "    \"\"\"You are a Reddit post generator.\n",
    "User: \n",
    "Subreddit: $subreddit \n",
    "Author: $author \n",
    "Media: $media \n",
    "Title: $title \n",
    "Write the Reddit post.\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "def contains_letter(s):\n",
    "    return any(c.isalpha() for c in s)\n",
    "\n",
    "def gen_valid_first_character(include_digits=True):\n",
    "    if include_digits and random.random() < 0.5:\n",
    "        return random.choice(string.digits)\n",
    "    return random.choice(string.ascii_letters)\n",
    "\n",
    "\n",
    "VALID_MEDIA = [\"image\", \"video\", \"text\", \"article\"] # articles are links to external sites\n",
    "TAGS = {\n",
    "    \"Subreddit\": {\n",
    "        \"TAG\": \"[SUBREDDIT]\",\n",
    "        \"CONSTRAINT\": lambda x: x.startswith(\"/r/\") and len(x) > len(\"/r/\") + 3 and contains_letter(x) and len(x) <= len(\"/r/\") + 21,\n",
    "        \"HELPER\": lambda x: f\"/r/{gen_valid_first_character(include_digits=False)}\",\n",
    "    },\n",
    "    \"Author\": {\n",
    "        \"TAG\": \"[AUTHOR]\",\n",
    "        \"CONSTRAINT\": lambda x: len(x) >= 3 and contains_letter(x) and len(x) <= 23,\n",
    "        \"HELPER\": lambda x: gen_valid_first_character(include_digits=True),\n",
    "    },\n",
    "    \"Media\": {\n",
    "        \"TAG\": \"[MEDIA]\",\n",
    "        \"CONSTRAINT\": lambda x: x in VALID_MEDIA,\n",
    "        \"HELPER\": lambda x: x,\n",
    "    },\n",
    "    \"Title\": {\n",
    "        \"TAG\": \"[TITLE]\",\n",
    "        \"CONSTRAINT\": lambda x: len(x) > 0 and contains_letter(x) and len(x) <= 300,\n",
    "        \"HELPER\": lambda x: x,\n",
    "    },\n",
    "    \"EOS\": {\n",
    "        \"TAG\": \"Write the Reddit post.\\nAssistant:\",\n",
    "        \"CONSTRAINT\": lambda x: x,\n",
    "        \"HELPER\": lambda x: x,\n",
    "    },\n",
    "}\n",
    "\n",
    "POST_TAGS_ORDER_OP = [\n",
    "    TAGS[\"Subreddit\"][\"TAG\"],\n",
    "    TAGS[\"Author\"][\"TAG\"],\n",
    "    TAGS[\"Media\"][\"TAG\"],\n",
    "    TAGS[\"Title\"][\"TAG\"],\n",
    "    TAGS[\"EOS\"][\"TAG\"],\n",
    "]  # order matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a Reddit post generator.\n",
      "User: \n",
      "Subreddit: /r/EarthPorn \n",
      "Author: 1989_Girl \n",
      "Media: article \n",
      "Title: 20,000+ acres of California desert will be protected from development thanks to the state's largest conservation deal in decades \n",
      "Write the Reddit post.\n",
      "Assistant:\n",
      " \n",
      "California has just made history with its biggest land conservation deal ever â€” protecting over 20,000 acres (8,094 hectares) of pristine Mojave Desert wilderness from future development. The agreement between the state and two private companies is expected to help preserve some of America's most unique wildlife habitats while also providing new opportunities for outdoor recreation.\n",
      "The project involves purchasing two large tracts of land north of Los Angeles that were previously owned by Tejon Ranch Company and Lennar Corporation. Together, these properties form what's known as the \"Tehachapi Mountains\" region, which includes rugged canyons, towering peaks, and other stunning natural features.\n",
      "According to Governor Gavin Newsom, who announced the deal on Monday, this purchase represents an important step forward in his administration's efforts to safeguard California's environment and natural resources.\n",
      "\"This historic agreement not only preserves thousands of acres of beautiful open space,\" he said in a statement, \"but it also provides critical habitat for rare and endangered species like the California condor.\"\n",
      "Under the terms of the agreement, the state will pay $USD75 million ($AUD106 million) upfront to acquire the first parcel of land from Tejon Ranch Company. It will then contribute another $USD30 million ($AUD42 million) towards the second property once certain environmental conditions have been met. In total, the transaction is estimated to cost around $USD100 million ($AUD138 million).\n",
      "But despite the high price tag, environmentalists say the benefits of this deal far outweigh any costs involved. By protecting such vast swathes of wildland, they argue, we're helping to ensure the long-term survival of countless plant and animal species that rely on intact ecosystems like these.\n",
      "\"We applaud the governor and all parties involved for their leadership in conserving this remarkable landscape,\" said Jeff Kuyper, executive director of the Los Padres ForestWatch advocacy group. \"This agreement sets a precedent for how public agencies should work together to protect our remaining wildlands and provide recreational access for Californians.\"\n",
      "In addition to protecting vital habitat for endangered species like the California condor, the newly acquired lands will also offer new opportunities for hiking, camping, horseback riding, and other forms of outdoor recreation. This could help boost local economies and create jobs in communities that depend on tourism and related industries.\n",
      "Overall, experts say this latest land conservation effort shows that there's still hope for preserving valuable natural areas even amidst the pressures of urbanization and industrialization. And if more deals like this one continue to be struck across California and beyond, perhaps we can look forward to a brighter future where both people and nature thrive side by side.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def get_up_to_tag_line(prompt, tag):\n",
    "    try:\n",
    "        sub_index = prompt.index(tag)\n",
    "    except ValueError:\n",
    "        print(\"Error: tag not found\")\n",
    "        return -1\n",
    "\n",
    "    # get last \\n before tag\n",
    "    last_newline_index = prompt.rfind(\"\\n\", 0, sub_index)\n",
    "\n",
    "    if last_newline_index == -1:\n",
    "        last_newline_index = 0\n",
    "    # remove  from last_newline_index to newline_index\n",
    "    prompt = prompt[:last_newline_index]\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def get_up_to_tag(prompt, tag):\n",
    "    try:\n",
    "        sub_index = prompt.index(tag)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "    prompt = prompt[:sub_index]\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "def generate_post(\n",
    "    **options\n",
    "):\n",
    "    default_options = {\n",
    "        \"subreddit\": TAGS[\"Subreddit\"][\"TAG\"],\n",
    "        \"author\": TAGS[\"Author\"][\"TAG\"],\n",
    "        \"media\": TAGS[\"Media\"][\"TAG\"],\n",
    "        \"title\": TAGS[\"Title\"][\"TAG\"],\n",
    "    }\n",
    "    options = {**default_options, **options}\n",
    "    prompt_full = POST_TEMPLATE.substitute(\n",
    "        options\n",
    "    )\n",
    "\n",
    "    # loop over tags in order\n",
    "    for tag in POST_TAGS_ORDER_OP:\n",
    "        if tag == TAGS[\"EOS\"][\"TAG\"]:\n",
    "            # add EOS tag\n",
    "            #prompt_full = f\"{prompt_full}\\n{tag}\"\n",
    "            break\n",
    "        prompt = get_up_to_tag(prompt_full, tag)\n",
    "        if prompt == -1:\n",
    "            continue  # skip tag if not found\n",
    "        #print(prompt)\n",
    "\n",
    "        # get tag key from tag value\n",
    "        for temp_tag_key, tag_obj in TAGS.items():\n",
    "            if tag_obj[\"TAG\"] == tag:\n",
    "                tag_key = temp_tag_key\n",
    "                next_tag_value = POST_TAGS_ORDER_OP[POST_TAGS_ORDER_OP.index(tag) + 1]\n",
    "                continue\n",
    "            if tag_obj[\"TAG\"] == next_tag_value:\n",
    "                next_tag_key = temp_tag_key\n",
    "                break\n",
    "\n",
    "        # print(\"Tag: \" + tag_key)\n",
    "        #print(f\"\"\"generate from here to: '\\\\n'\"\"\")\n",
    "        #print()\n",
    "        streaming_generator.set_stop_conditions(\n",
    "            [\"\\n\", \"\\nUser:\", tokenizer.eos_token_id]\n",
    "        )\n",
    "        valid_output = False\n",
    "        while not valid_output:\n",
    "            helper_starter_char = TAGS[tag_key][\"HELPER\"](\"\")\n",
    "            if tag == \"[MEDIA]\":\n",
    "                # random valid media\n",
    "                output = random.choice(VALID_MEDIA)\n",
    "            else:\n",
    "                output = generate_with_lora(f\"{prompt}{helper_starter_char}\", lora, 250)\n",
    "            output = output.strip()\n",
    "            output = helper_starter_char + output\n",
    "            #print(f\"generated output: {output}\")\n",
    "            valid_output = TAGS[tag_key][\"CONSTRAINT\"](output)\n",
    "                \n",
    "        # replace tag with output\n",
    "        prompt_full = prompt_full.replace(tag, output)\n",
    "        #prompt = f\"{prompt}{output} \\n{next_tag_key}:}\"\n",
    "\n",
    "    #print(prompt_full)\n",
    "    streaming_generator.set_stop_conditions(\n",
    "            [\"\\nUser:\", tokenizer.eos_token_id]\n",
    "        )\n",
    "    return prompt_full, generate_with_lora(prompt_full, lora, len(prompt_full) + 500)\n",
    "\n",
    "\n",
    "prompt, post = generate_post()\n",
    "print(prompt)\n",
    "print(post)\n",
    "# generate_post(subreddit=\"r/aww\", author=\"u/aww\", media=\"https://i.redd.it/1q2w3e4r5t6y.jpg\", title=\"Cute doggo\")\n",
    "#generate_post(subreddit=\"r/aww\", author=\"u/aww\", media=\"https://i.redd.it/1q2w3e4r5t6y.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingLlama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
